# Impairing and Improving Open-set Recognition with Adversarial Attacks
This is the code for our BSc thesis titled *Impairing and Improving Open-set Recognition with Adversarial Attacks*. Here we guide you through the process of reproducing our experimental results.

# An Overview of the Code
Our code is built upon the code by Vaze et al. from their paper [Open-Set Recognition: a Good Closed-Set Classifier is All You Need?](https://www.robots.ox.ac.uk/~vgg/research/osr/). Their code is found in the folder `osr_closed_set_all_you_need_main` and it is explained in their README file. The other folders and files in this repo is ours (we only modified the `classifier32.py` file very slightly). 

Shortly summarized here are the contents of each folder:
* `datasets` contain the part of Tiny ImageNet we experiment with.
* `grad_norms` contain the log-MSP gradient norms we inspected.
* `logits` contain the logits of all images we experiment with for a variety of attacks and epsilon-values (also the plain logits with no attack).
* `notebooks` contain notebooks that can be executed to reproduce our results.
* `our_modules` contain tools we made.
    * `adv_tools` can be used for adversarial attacks.
    * `eval_tools` can be used to evaluate obtain a variety of statistics of logits. The tools can for instance load logits and evaluate their AUROC with different scoring rules.
    * `plot_tools`can be used to generate the plots seen in our thesis.
    * `tin_tools` contain tools specific to the Tiny ImageNet. 
* `visualizations` contain plots and images generated by `notebooks/final_visualisations.ipynb`. These are the images/plots shown in the thesis.
* `classifier32.py`is the model we used as a backbone.
* `config.py`is Vaze et al.'s config file. We don't really use this so please ignore it unless you wish to modify their code.

# Running the Code
We have run the code locally on apple computers using apple silicon (M1/M2). The following steps show how to run our code on such a system.

## 1. Create a conda environment
`> conda create --name <env_name> --file requirements.txt`

## 2. Reproduce some results from Vaze et al. to check that the model works
Open `notebooks/reproduce_paper_results.ipynb` and run all cells. Here the CSR accuracy and MLS OSR AUROC is evaluated as evaluated by Vaze et al. The CSR accuracy is found in table 5 (second-to-last row) and the MLS OSR AUROC is found in table 1 (bottom row) of their [paper](https://www.robots.ox.ac.uk/~vgg/research/osr/).

## 3. Generate our Vizualizations
Open `notebooks/final_visualisations.ipynb` and run all cells.

## OPTIONAL; Save logits for new epsilon/attacks
The `notebooks/save_logits.ipynb` can be used to perform attacks and save the logits. This repo contains all the logits we generated so this is not need for reproducing our results. The notebook can NOT simply be run to obtain the logits we have but it can be used as inspiration of to use our tools to save logits.

