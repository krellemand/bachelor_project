{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving logits of original and adversarially attacked inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"hack\" below allows absolute path imports as if the notebook was a py-file run with `python -m abs.path.to.file.filename`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "root_dir = !cd .. &&pwd\n",
    "root_dir = root_dir[0] + \"/\"\n",
    "sys.path.insert(0, root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/gunder/Desktop/bachelor_project/\n"
     ]
    }
   ],
   "source": [
    "print(root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from models.classifier32 import classifier32\n",
    "from our_modules.tin_tools import get_avg_osr_auroc_across_splits\n",
    "from our_modules.adv_tools import fp_osr_fgsm, fn_osr_fgsm\n",
    "from our_modules.tin_tools import transform_range as tin_clip_range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: mps\n"
     ]
    }
   ],
   "source": [
    "if sys.platform == 'darwin':\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    gpu = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda:0\" if gpu else \"cpu\")\n",
    "\n",
    "print(\"device:\", device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tiny-imagenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_pretrained_weights_folder = root_dir + \"pretrained_weights/\"\n",
    "tin_val_root_dir = root_dir + \"datasets/tiny-imagenet-200/val/images/\"\n",
    "tin_logits_dir = root_dir + \"logits/tinyimagenet/\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving plain logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_avg_osr_auroc_across_splits(path_to_pretrained_weights_folder, tin_val_root_dir, device, logdir=tin_logits_dir + \"plain/\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Savining Advesarial Attacks Logits"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FGSM for different epsilon"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgsm_eps_experiment(eps_list, fgsm, logdir, number_of_splits=5):\n",
    "    for eps in eps_list:\n",
    "        attack = (lambda x, y, model: fgsm(model, x, eps=eps, clip_range=tin_clip_range))\n",
    "        get_avg_osr_auroc_across_splits(path_to_pretrained_weights_folder, tin_val_root_dir, device, logdir + f\"eps_{eps:.3}/\", adv_attack=attack, number_of_splits=number_of_splits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0200, 0.0309, 0.0477, 0.0737, 0.1138, 0.1758, 0.2714, 0.4192, 0.6475,\n",
       "        1.0000])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.logspace(np.log10(0.02),np.log10(1), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]/Users/gunder/Desktop/bachelor_project/our_modules/adv_tools.py:25: UserWarning: The operator 'aten::linalg_vector_norm' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1670525849783/work/aten/src/ATen/mps/MPSFallback.mm:11.)\n",
      "  return fgsm(model, x, torch.zeros(len(x)), eps, lambda y_hat, y: torch.linalg.norm(y_hat, dim=-1, ord=torch.inf), clip_range=clip_range)\n",
      "100%|██████████| 1/1 [02:32<00:00, 152.68s/it]\n",
      "100%|██████████| 1/1 [01:59<00:00, 119.92s/it]\n",
      "100%|██████████| 1/1 [02:02<00:00, 122.79s/it]\n",
      "100%|██████████| 1/1 [01:59<00:00, 119.17s/it]\n",
      "100%|██████████| 1/1 [01:58<00:00, 118.93s/it]\n",
      "100%|██████████| 1/1 [01:59<00:00, 119.41s/it]\n",
      "100%|██████████| 1/1 [09:38<00:00, 578.30s/it]\n",
      "100%|██████████| 1/1 [02:32<00:00, 152.30s/it]\n",
      "  0%|          | 0/1 [01:46<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/gunder/Desktop/bachelor_project/notebooks/save_logits.ipynb Cell 18\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/gunder/Desktop/bachelor_project/notebooks/save_logits.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m fgsm_eps_experiment(np\u001b[39m.\u001b[39;49mlogspace(np\u001b[39m.\u001b[39;49mlog10(\u001b[39m0.02\u001b[39;49m),np\u001b[39m.\u001b[39;49mlog10(\u001b[39m1\u001b[39;49m), \u001b[39m10\u001b[39;49m), fn_osr_fgsm, tin_logits_dir \u001b[39m+\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mfn/fgsm/\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m1\u001b[39;49m)\n",
      "\u001b[1;32m/Users/gunder/Desktop/bachelor_project/notebooks/save_logits.ipynb Cell 18\u001b[0m in \u001b[0;36mfgsm_eps_experiment\u001b[0;34m(eps_list, fgsm, logdir, number_of_splits)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gunder/Desktop/bachelor_project/notebooks/save_logits.ipynb#X23sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m eps \u001b[39min\u001b[39;00m eps_list:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gunder/Desktop/bachelor_project/notebooks/save_logits.ipynb#X23sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     attack \u001b[39m=\u001b[39m (\u001b[39mlambda\u001b[39;00m x, y, model: fgsm(model, x, eps\u001b[39m=\u001b[39meps, clip_range\u001b[39m=\u001b[39mtin_clip_range))\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/gunder/Desktop/bachelor_project/notebooks/save_logits.ipynb#X23sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     get_avg_osr_auroc_across_splits(path_to_pretrained_weights_folder, tin_val_root_dir, device, logdir \u001b[39m+\u001b[39;49m \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39meps_\u001b[39;49m\u001b[39m{\u001b[39;49;00meps\u001b[39m}\u001b[39;49;00m\u001b[39m/\u001b[39;49m\u001b[39m\"\u001b[39;49m, adv_attack\u001b[39m=\u001b[39;49mattack, number_of_splits\u001b[39m=\u001b[39;49mnumber_of_splits)\n",
      "File \u001b[0;32m~/Desktop/bachelor_project/our_modules/tin_tools.py:159\u001b[0m, in \u001b[0;36mget_avg_osr_auroc_across_splits\u001b[0;34m(path_to_pretrained_weights_folder, tin_val_root_dir, device, logdir, batch_size, shuffle, adv_attack, number_of_splits)\u001b[0m\n\u001b[1;32m    157\u001b[0m     model \u001b[39m=\u001b[39m get_model_for_split(split_num, path_to_pretrained_weights_folder, device\u001b[39m=\u001b[39mdevice)\n\u001b[1;32m    158\u001b[0m     dataloader \u001b[39m=\u001b[39m get_osr_dataloader_for_split(split_num, tin_val_root_dir, batch_size\u001b[39m=\u001b[39mbatch_size, shuffle\u001b[39m=\u001b[39mshuffle)\n\u001b[0;32m--> 159\u001b[0m     auroc \u001b[39m=\u001b[39m evaluate_osr_auroc(model, dataloader, split_num, device\u001b[39m=\u001b[39;49mdevice, logdir\u001b[39m=\u001b[39;49mlogdir, adv_attack\u001b[39m=\u001b[39;49madv_attack)\n\u001b[1;32m    160\u001b[0m     aurocs \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m auroc,\n\u001b[1;32m    162\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msum\u001b[39m(aurocs)\u001b[39m/\u001b[39m\u001b[39mlen\u001b[39m(aurocs)\n",
      "File \u001b[0;32m~/Desktop/bachelor_project/our_modules/tin_tools.py:135\u001b[0m, in \u001b[0;36mevaluate_osr_auroc\u001b[0;34m(model, dataloader, split_num, device, logdir, adv_attack)\u001b[0m\n\u001b[1;32m    133\u001b[0m target_batch \u001b[39m=\u001b[39m get_osr_targets(target_batch, split_num)\n\u001b[1;32m    134\u001b[0m target_batch \u001b[39m=\u001b[39m target_batch\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m--> 135\u001b[0m input_batch \u001b[39m=\u001b[39m adv_attack(input_batch, target_batch, model) \u001b[39m# perform the adversarial attack\u001b[39;00m\n\u001b[1;32m    136\u001b[0m logits \u001b[39m=\u001b[39m model(input_batch)\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mto(\u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    137\u001b[0m all_logits \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m logits,\n",
      "\u001b[1;32m/Users/gunder/Desktop/bachelor_project/notebooks/save_logits.ipynb Cell 18\u001b[0m in \u001b[0;36mfgsm_eps_experiment.<locals>.<lambda>\u001b[0;34m(x, y, model)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gunder/Desktop/bachelor_project/notebooks/save_logits.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfgsm_eps_experiment\u001b[39m(eps_list, fgsm, logdir, number_of_splits\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gunder/Desktop/bachelor_project/notebooks/save_logits.ipynb#X23sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mfor\u001b[39;00m eps \u001b[39min\u001b[39;00m eps_list:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/gunder/Desktop/bachelor_project/notebooks/save_logits.ipynb#X23sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m         attack \u001b[39m=\u001b[39m (\u001b[39mlambda\u001b[39;00m x, y, model: fgsm(model, x, eps\u001b[39m=\u001b[39;49meps, clip_range\u001b[39m=\u001b[39;49mtin_clip_range))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gunder/Desktop/bachelor_project/notebooks/save_logits.ipynb#X23sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m         get_avg_osr_auroc_across_splits(path_to_pretrained_weights_folder, tin_val_root_dir, device, logdir \u001b[39m+\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39meps_\u001b[39m\u001b[39m{\u001b[39;00meps\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m, adv_attack\u001b[39m=\u001b[39mattack, number_of_splits\u001b[39m=\u001b[39mnumber_of_splits)\n",
      "File \u001b[0;32m~/Desktop/bachelor_project/our_modules/adv_tools.py:25\u001b[0m, in \u001b[0;36mfn_osr_fgsm\u001b[0;34m(model, x, eps, clip_range)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfn_osr_fgsm\u001b[39m(model, x, eps\u001b[39m=\u001b[39m\u001b[39m0.05\u001b[39m, clip_range\u001b[39m=\u001b[39m(\u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m)):\n\u001b[0;32m---> 25\u001b[0m     \u001b[39mreturn\u001b[39;00m fgsm(model, x, torch\u001b[39m.\u001b[39;49mzeros(\u001b[39mlen\u001b[39;49m(x)), eps, \u001b[39mlambda\u001b[39;49;00m y_hat, y: torch\u001b[39m.\u001b[39;49mlinalg\u001b[39m.\u001b[39;49mnorm(y_hat, dim\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39mord\u001b[39;49m\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49minf), clip_range\u001b[39m=\u001b[39;49mclip_range)\n",
      "File \u001b[0;32m~/Desktop/bachelor_project/our_modules/adv_tools.py:14\u001b[0m, in \u001b[0;36mfgsm\u001b[0;34m(model, xs, ys, eps, loss_func, clip_range)\u001b[0m\n\u001b[1;32m     12\u001b[0m     x\u001b[39m.\u001b[39mrequires_grad \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     loss \u001b[39m=\u001b[39m loss_func(model(x[\u001b[39mNone\u001b[39;00m]), y)\n\u001b[0;32m---> 14\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     15\u001b[0m     output\u001b[39m.\u001b[39mappend((x \u001b[39m+\u001b[39m eps\u001b[39m*\u001b[39mtorch\u001b[39m.\u001b[39msign(x\u001b[39m.\u001b[39mgrad))[\u001b[39mNone\u001b[39;00m])\n\u001b[1;32m     16\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mclip(torch\u001b[39m.\u001b[39mcat(output), clip_range[\u001b[39m0\u001b[39m], clip_range[\u001b[39m1\u001b[39m])\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    489\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    490\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fgsm_eps_experiment(np.logspace(np.log10(0.02),np.log10(1), 10), fn_osr_fgsm, tin_logits_dir + \"fn/fgsm/\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]/Users/gunder/Desktop/bachelor_project/our_modules/adv_tools.py:25: UserWarning: The operator 'aten::linalg_vector_norm' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1670525849783/work/aten/src/ATen/mps/MPSFallback.mm:11.)\n",
      "  return fgsm(model, x, torch.zeros(len(x)), -eps, lambda y_hat, y: torch.linalg.norm(y_hat, dim=-1, ord=None))\n",
      "100%|██████████| 5/5 [15:44<00:00, 188.92s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7287193666666666"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get_avg_osr_auroc_across_splits(path_to_pretrained_weights_folder, tin_val_root_dir, device, logdir=root_dir + \"logits/tinyimagenet/\", adv_attack=fgsm_fp_attack, adv_attack_name='fgsm_fp_attack')\n",
    "get_avg_osr_auroc_across_splits(path_to_pretrained_weights_folder, tin_val_root_dir, device, logdir=root_dir + \"logits/tinyimagenet/\", adv_attack=fgsm_fn_attack, adv_attack_name='fgsm_fn_attack')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
