{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving logits of original and adversarially attacked inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"hack\" below allows absolute path imports as if the notebook was a py-file run with `python -m abs.path.to.file.filename`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "root_dir = !cd .. &&pwd\n",
    "root_dir = root_dir[0] + \"/\"\n",
    "sys.path.insert(0, root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/gunder/Desktop/bachelor_project/\n"
     ]
    }
   ],
   "source": [
    "print(root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from models.classifier32 import classifier32\n",
    "\n",
    "from our_modules.tin_tools import get_avg_osr_auroc_across_splits\n",
    "from our_modules.tin_tools import transform_range as tin_clip_range\n",
    "\n",
    "from our_modules.adv_tools import fp_osr_fgsm, fn_osr_fgsm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: mps\n"
     ]
    }
   ],
   "source": [
    "if sys.platform == 'darwin':\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    gpu = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda:0\" if gpu else \"cpu\")\n",
    "\n",
    "print(\"device:\", device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tiny-imagenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_pretrained_weights_folder = root_dir + \"pretrained_weights/\"\n",
    "tin_val_root_dir = root_dir + \"datasets/tiny-imagenet-200/val/images/\"\n",
    "tin_logits_dir = root_dir + \"logits/tinyimagenet/\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving plain logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_avg_osr_auroc_across_splits(path_to_pretrained_weights_folder, tin_val_root_dir, device, logdir=tin_logits_dir + \"plain/\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Savining Advesarial Attacks Logits"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FGSM for different epsilon"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgsm_eps_experiment(eps_list, fgsm, logdir, number_of_splits=5, **fgsm_kwargs):\n",
    "    for eps in eps_list:\n",
    "        attack = (lambda x, y, model: fgsm(model, x, eps=eps, clip_range=tin_clip_range, **fgsm_kwargs))\n",
    "        get_avg_osr_auroc_across_splits(path_to_pretrained_weights_folder, tin_val_root_dir, device, logdir + f\"eps_{eps:.3}/\", adv_attack=attack, number_of_splits=number_of_splits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = torch.linspace(0.001,1, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fgsm_eps_experiment(eps, fn_osr_fgsm, tin_logits_dir + \"fn/fgsm/\", 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FP"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2-norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]/Users/gunder/Desktop/bachelor_project/our_modules/adv_tools.py:29: UserWarning: The operator 'aten::linalg_vector_norm' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1670525849783/work/aten/src/ATen/mps/MPSFallback.mm:11.)\n",
      "  return fgsm(model, x, torch.zeros(len(x)), -eps, lambda y_hat, y: torch.linalg.norm(y_hat, dim=-1, ord=norm_ord),\n",
      "100%|██████████| 1/1 [01:49<00:00, 109.13s/it]\n",
      "100%|██████████| 1/1 [01:45<00:00, 105.90s/it]\n",
      "100%|██████████| 1/1 [01:45<00:00, 105.75s/it]\n",
      "100%|██████████| 1/1 [01:44<00:00, 104.60s/it]\n",
      "100%|██████████| 1/1 [01:44<00:00, 104.74s/it]\n",
      "100%|██████████| 1/1 [01:49<00:00, 109.30s/it]\n",
      "100%|██████████| 1/1 [01:47<00:00, 107.94s/it]\n",
      "100%|██████████| 1/1 [01:48<00:00, 108.10s/it]\n",
      "100%|██████████| 1/1 [01:48<00:00, 108.22s/it]\n",
      "100%|██████████| 1/1 [01:46<00:00, 106.62s/it]\n",
      "100%|██████████| 1/1 [01:47<00:00, 107.58s/it]\n",
      "100%|██████████| 1/1 [01:44<00:00, 105.00s/it]\n",
      "100%|██████████| 1/1 [01:41<00:00, 101.33s/it]\n",
      "100%|██████████| 1/1 [01:46<00:00, 106.28s/it]\n",
      "100%|██████████| 1/1 [01:46<00:00, 106.08s/it]\n",
      "100%|██████████| 1/1 [01:46<00:00, 106.22s/it]\n",
      "100%|██████████| 1/1 [01:45<00:00, 105.84s/it]\n",
      "100%|██████████| 1/1 [01:46<00:00, 106.25s/it]\n",
      "100%|██████████| 1/1 [01:45<00:00, 105.99s/it]\n",
      "100%|██████████| 1/1 [01:42<00:00, 102.85s/it]\n",
      "100%|██████████| 1/1 [01:46<00:00, 106.82s/it]\n",
      "100%|██████████| 1/1 [01:46<00:00, 106.47s/it]\n",
      "100%|██████████| 1/1 [01:46<00:00, 106.01s/it]\n",
      "100%|██████████| 1/1 [01:46<00:00, 106.38s/it]\n",
      "100%|██████████| 1/1 [01:46<00:00, 106.16s/it]\n",
      "100%|██████████| 1/1 [01:46<00:00, 106.50s/it]\n",
      "100%|██████████| 1/1 [01:42<00:00, 102.66s/it]\n",
      "100%|██████████| 1/1 [01:40<00:00, 100.96s/it]\n",
      "100%|██████████| 1/1 [01:40<00:00, 100.86s/it]\n",
      "100%|██████████| 1/1 [01:40<00:00, 100.08s/it]\n",
      "100%|██████████| 1/1 [01:39<00:00, 99.98s/it]\n",
      "100%|██████████| 1/1 [01:40<00:00, 100.72s/it]\n",
      "100%|██████████| 1/1 [01:41<00:00, 101.06s/it]\n",
      "100%|██████████| 1/1 [01:41<00:00, 101.32s/it]\n",
      "100%|██████████| 1/1 [01:41<00:00, 101.01s/it]\n",
      "100%|██████████| 1/1 [01:41<00:00, 101.24s/it]\n",
      "100%|██████████| 1/1 [01:41<00:00, 101.27s/it]\n",
      "100%|██████████| 1/1 [01:41<00:00, 101.23s/it]\n",
      "100%|██████████| 1/1 [01:41<00:00, 101.14s/it]\n",
      "100%|██████████| 1/1 [01:40<00:00, 100.92s/it]\n",
      "100%|██████████| 1/1 [01:41<00:00, 101.40s/it]\n",
      "100%|██████████| 1/1 [01:41<00:00, 101.11s/it]\n",
      "100%|██████████| 1/1 [01:41<00:00, 101.43s/it]\n",
      "100%|██████████| 1/1 [01:41<00:00, 101.03s/it]\n",
      "100%|██████████| 1/1 [01:40<00:00, 100.47s/it]\n",
      "100%|██████████| 1/1 [01:41<00:00, 101.13s/it]\n",
      "100%|██████████| 1/1 [01:41<00:00, 101.17s/it]\n",
      "100%|██████████| 1/1 [01:41<00:00, 101.15s/it]\n",
      "100%|██████████| 1/1 [01:41<00:00, 101.32s/it]\n",
      "100%|██████████| 1/1 [01:41<00:00, 101.33s/it]\n",
      "100%|██████████| 1/1 [01:53<00:00, 113.99s/it]\n",
      "100%|██████████| 1/1 [01:53<00:00, 113.89s/it]\n",
      "100%|██████████| 1/1 [01:53<00:00, 113.84s/it]\n",
      "100%|██████████| 1/1 [01:53<00:00, 113.72s/it]\n",
      "100%|██████████| 1/1 [01:54<00:00, 114.27s/it]\n",
      "100%|██████████| 1/1 [01:54<00:00, 114.03s/it]\n",
      "100%|██████████| 1/1 [01:53<00:00, 113.79s/it]\n",
      "100%|██████████| 1/1 [01:53<00:00, 113.76s/it]\n",
      "100%|██████████| 1/1 [01:54<00:00, 114.02s/it]\n",
      "100%|██████████| 1/1 [01:54<00:00, 114.13s/it]\n",
      "100%|██████████| 1/1 [01:53<00:00, 113.83s/it]\n",
      "100%|██████████| 1/1 [01:53<00:00, 113.93s/it]\n",
      "100%|██████████| 1/1 [01:54<00:00, 114.15s/it]\n",
      "100%|██████████| 1/1 [01:53<00:00, 113.66s/it]\n",
      "100%|██████████| 1/1 [01:53<00:00, 113.80s/it]\n",
      "100%|██████████| 1/1 [01:53<00:00, 113.82s/it]\n",
      "100%|██████████| 1/1 [01:54<00:00, 114.24s/it]\n",
      "100%|██████████| 1/1 [01:53<00:00, 113.88s/it]\n",
      "100%|██████████| 1/1 [01:53<00:00, 113.88s/it]\n",
      "100%|██████████| 1/1 [01:53<00:00, 113.53s/it]\n",
      "100%|██████████| 1/1 [01:53<00:00, 113.90s/it]\n",
      "100%|██████████| 1/1 [01:53<00:00, 113.87s/it]\n",
      "100%|██████████| 1/1 [01:53<00:00, 113.78s/it]\n",
      "100%|██████████| 1/1 [01:53<00:00, 113.67s/it]\n",
      "100%|██████████| 1/1 [01:53<00:00, 113.74s/it]\n",
      "100%|██████████| 1/1 [01:53<00:00, 113.70s/it]\n",
      "100%|██████████| 1/1 [01:53<00:00, 113.33s/it]\n",
      "100%|██████████| 1/1 [01:52<00:00, 112.96s/it]\n",
      "100%|██████████| 1/1 [01:53<00:00, 113.49s/it]\n",
      "100%|██████████| 1/1 [01:53<00:00, 113.37s/it]\n",
      "100%|██████████| 1/1 [01:53<00:00, 113.49s/it]\n",
      "100%|██████████| 1/1 [01:53<00:00, 113.49s/it]\n",
      "100%|██████████| 1/1 [01:53<00:00, 113.59s/it]\n",
      "100%|██████████| 1/1 [01:53<00:00, 113.60s/it]\n",
      "100%|██████████| 1/1 [01:53<00:00, 113.64s/it]\n",
      "100%|██████████| 1/1 [01:53<00:00, 113.38s/it]\n",
      "100%|██████████| 1/1 [01:53<00:00, 113.39s/it]\n",
      "100%|██████████| 1/1 [01:53<00:00, 113.62s/it]\n",
      "100%|██████████| 1/1 [01:53<00:00, 113.54s/it]\n",
      "100%|██████████| 1/1 [01:53<00:00, 113.40s/it]\n",
      "100%|██████████| 1/1 [01:53<00:00, 113.47s/it]\n",
      "100%|██████████| 1/1 [01:53<00:00, 113.49s/it]\n",
      "100%|██████████| 1/1 [01:53<00:00, 113.59s/it]\n",
      "100%|██████████| 1/1 [01:53<00:00, 113.40s/it]\n",
      "100%|██████████| 1/1 [01:53<00:00, 113.71s/it]\n",
      "100%|██████████| 1/1 [01:53<00:00, 113.72s/it]\n",
      "100%|██████████| 1/1 [01:53<00:00, 113.65s/it]\n",
      "100%|██████████| 1/1 [01:53<00:00, 113.57s/it]\n",
      "100%|██████████| 1/1 [01:53<00:00, 113.44s/it]\n",
      "100%|██████████| 1/1 [01:53<00:00, 113.64s/it]\n"
     ]
    }
   ],
   "source": [
    "fgsm_eps_experiment(eps_list=eps, fgsm=fp_osr_fgsm, logdir=tin_logits_dir + \"fp/fgsm/two_norm/\", number_of_splits=1, norm_ord=None)\n",
    "fgsm_eps_experiment(eps_list=eps, fgsm=fp_osr_fgsm, logdir=tin_logits_dir + \"fp/fgsm/inf_norm/\", number_of_splits=1, norm_ord=torch.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]/Users/gunder/Desktop/bachelor_project/our_modules/adv_tools.py:25: UserWarning: The operator 'aten::linalg_vector_norm' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1670525849783/work/aten/src/ATen/mps/MPSFallback.mm:11.)\n",
      "  return fgsm(model, x, torch.zeros(len(x)), -eps, lambda y_hat, y: torch.linalg.norm(y_hat, dim=-1, ord=None))\n",
      "100%|██████████| 5/5 [15:44<00:00, 188.92s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7287193666666666"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get_avg_osr_auroc_across_splits(path_to_pretrained_weights_folder, tin_val_root_dir, device, logdir=root_dir + \"logits/tinyimagenet/\", adv_attack=fgsm_fp_attack, adv_attack_name='fgsm_fp_attack')\n",
    "# get_avg_osr_auroc_across_splits(path_to_pretrained_weights_folder, tin_val_root_dir, device, logdir=root_dir + \"logits/tinyimagenet/\", adv_attack=fgsm_fn_attack, adv_attack_name='fgsm_fn_attack')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bsc",
   "language": "python",
   "name": "bsc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
