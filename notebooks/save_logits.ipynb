{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving logits of original and adversarially attacked inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"hack\" below allows absolute path imports as if the notebook was a py-file run with `python -m abs.path.to.file.filename`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "root_dir = !cd .. &&pwd\n",
    "root_dir = root_dir[0] + \"/\"\n",
    "sys.path.insert(0, root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/gunder/Desktop/bachelor_project/\n"
     ]
    }
   ],
   "source": [
    "print(root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from models.classifier32 import classifier32\n",
    "\n",
    "from our_modules.tin_tools import get_avg_osr_auroc_across_splits\n",
    "from our_modules.tin_tools import transform_range as tin_clip_range\n",
    "from our_modules.tin_tools import save_grad_norms_across_splits\n",
    "from our_modules.tin_tools import save_informed_attack\n",
    "\n",
    "from our_modules.adv_tools import fp_osr_fgsm, fn_osr_fgsm, fp_osr_fgsm_sum_exp, fn_osr_fgsm_log_msp, fn_osr_fgsm_sum_exp\n",
    "from our_modules.adv_tools import log_msp_loss\n",
    "from our_modules.adv_tools import iterative_attack\n",
    "from our_modules.adv_tools import norm_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: mps\n"
     ]
    }
   ],
   "source": [
    "if sys.platform == 'darwin':\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    gpu = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda:0\" if gpu else \"cpu\")\n",
    "\n",
    "print(\"device:\", device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tiny-imagenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_pretrained_weights_folder = root_dir + \"pretrained_weights/\"\n",
    "tin_val_root_dir = root_dir + \"datasets/tiny-imagenet-200/val/images/\"\n",
    "tin_logits_dir = root_dir + \"logits/tinyimagenet/\"\n",
    "tin_grad_norms_dir = root_dir + 'grad_norms/tinyimagenet/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving plain logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_avg_osr_auroc_across_splits(path_to_pretrained_weights_folder, tin_val_root_dir, device, logdir=tin_logits_dir + \"plain/\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Savining Advesarial Attacks Logits"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FGSM for different epsilon"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgsm_eps_experiment(eps_list, fgsm, logdir, number_of_splits=5, **fgsm_kwargs):\n",
    "    for eps in eps_list:\n",
    "        attack = (lambda yhat, y, model: fgsm(model, yhat, eps=eps, clip_range=tin_clip_range, **fgsm_kwargs))\n",
    "        get_avg_osr_auroc_across_splits(path_to_pretrained_weights_folder, tin_val_root_dir, device, logdir + f\"eps_{eps:.3}/\", adv_attack=attack, number_of_splits=number_of_splits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.1233e-05, device='mps:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0., device='mps:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0086, device='mps:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0086, device='mps:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0194, device='mps:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0., device='mps:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0194, device='mps:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0194, device='mps:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0194, device='mps:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0194, device='mps:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0194, device='mps:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0194, device='mps:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0., device='mps:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0086, device='mps:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0194, device='mps:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0194, device='mps:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0194, device='mps:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0194, device='mps:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0., device='mps:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0194, device='mps:0', grad_fn=<MaxBackward1>)\n",
      "torch.Size([20, 3, 64, 64])\n",
      "tensor(0.0194, device='mps:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0., device='mps:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0194, device='mps:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3.1233e-05, device='mps:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0194, device='mps:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3.1233e-05, device='mps:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0194, device='mps:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3.1233e-05, device='mps:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0., device='mps:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0194, device='mps:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0., device='mps:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0194, device='mps:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0194, device='mps:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0086, device='mps:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0086, device='mps:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0194, device='mps:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0086, device='mps:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0., device='mps:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0194, device='mps:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0194, device='mps:0', grad_fn=<MaxBackward1>)\n",
      "torch.Size([20, 3, 64, 64])\n",
      "tensor(0.0194, device='mps:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3.1233e-05, device='mps:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0194, device='mps:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0., device='mps:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0194, device='mps:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0194, device='mps:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0194, device='mps:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0., device='mps:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0., device='mps:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0194, device='mps:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0086, device='mps:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0194, device='mps:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0194, device='mps:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0194, device='mps:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0194, device='mps:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0194, device='mps:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0086, device='mps:0', grad_fn=<MaxBackward1>)\n",
      "tensor(3.1233e-05, device='mps:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0194, device='mps:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0194, device='mps:0', grad_fn=<MaxBackward1>)\n",
      "torch.Size([20, 3, 64, 64])\n",
      "tensor(0.0194, device='mps:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0194, device='mps:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0194, device='mps:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0194, device='mps:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0194, device='mps:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0194, device='mps:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0194, device='mps:0', grad_fn=<MaxBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:26<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0194, device='mps:0', grad_fn=<MaxBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/gunder/Desktop/bachelor_project/notebooks/save_logits.ipynb Cell 17\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gunder/Desktop/bachelor_project/notebooks/save_logits.ipynb#X40sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m attack \u001b[39m=\u001b[39m (\u001b[39mlambda\u001b[39;00m x, y, model: iterative_attack(model, x, y, loss_func\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m yhat, y: torch\u001b[39m.\u001b[39mmax(yhat), torch_optim\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mRprop, clip_range\u001b[39m=\u001b[39mtin_clip_range, return_step\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, max_iter\u001b[39m=\u001b[39m\u001b[39m25\u001b[39m, step_sizes\u001b[39m=\u001b[39m(\u001b[39m1e-06\u001b[39m, \u001b[39m5e-03\u001b[39m)))\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/gunder/Desktop/bachelor_project/notebooks/save_logits.ipynb#X40sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m get_avg_osr_auroc_across_splits(path_to_pretrained_weights_folder, tin_val_root_dir, device, tin_logits_dir \u001b[39m+\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mfn/ia/test/\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m20\u001b[39;49m, shuffle\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, adv_attack\u001b[39m=\u001b[39;49mattack, number_of_splits\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[0;32m~/Desktop/bachelor_project/our_modules/tin_tools.py:139\u001b[0m, in \u001b[0;36mget_avg_osr_auroc_across_splits\u001b[0;34m(path_to_pretrained_weights_folder, tin_val_root_dir, device, logdir, batch_size, shuffle, adv_attack, number_of_splits)\u001b[0m\n\u001b[1;32m    137\u001b[0m     model \u001b[39m=\u001b[39m get_model_for_split(split_num, path_to_pretrained_weights_folder, device\u001b[39m=\u001b[39mdevice)\n\u001b[1;32m    138\u001b[0m     dataloader \u001b[39m=\u001b[39m get_osr_dataloader_for_split(split_num, tin_val_root_dir, batch_size\u001b[39m=\u001b[39mbatch_size, shuffle\u001b[39m=\u001b[39mshuffle)\n\u001b[0;32m--> 139\u001b[0m     auroc \u001b[39m=\u001b[39m evaluate_osr_auroc(model, dataloader, split_num, device\u001b[39m=\u001b[39;49mdevice, logdir\u001b[39m=\u001b[39;49mlogdir, adv_attack\u001b[39m=\u001b[39;49madv_attack)\n\u001b[1;32m    140\u001b[0m     aurocs \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m auroc,\n\u001b[1;32m    142\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msum\u001b[39m(aurocs)\u001b[39m/\u001b[39m\u001b[39mlen\u001b[39m(aurocs)\n",
      "File \u001b[0;32m~/Desktop/bachelor_project/our_modules/tin_tools.py:115\u001b[0m, in \u001b[0;36mevaluate_osr_auroc\u001b[0;34m(model, dataloader, split_num, device, logdir, adv_attack)\u001b[0m\n\u001b[1;32m    113\u001b[0m target_batch \u001b[39m=\u001b[39m get_osr_targets(target_batch, split_num)\n\u001b[1;32m    114\u001b[0m target_batch \u001b[39m=\u001b[39m target_batch\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m--> 115\u001b[0m input_batch \u001b[39m=\u001b[39m adv_attack(input_batch, target_batch, model) \u001b[39m# perform the adversarial attack\u001b[39;00m\n\u001b[1;32m    116\u001b[0m logits \u001b[39m=\u001b[39m model(input_batch)\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mto(\u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    117\u001b[0m all_logits \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m logits,\n",
      "\u001b[1;32m/Users/gunder/Desktop/bachelor_project/notebooks/save_logits.ipynb Cell 17\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x, y, model)\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/gunder/Desktop/bachelor_project/notebooks/save_logits.ipynb#X40sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m attack \u001b[39m=\u001b[39m (\u001b[39mlambda\u001b[39;00m x, y, model: iterative_attack(model, x, y, loss_func\u001b[39m=\u001b[39;49m\u001b[39mlambda\u001b[39;49;00m yhat, y: torch\u001b[39m.\u001b[39;49mmax(yhat), torch_optim\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49moptim\u001b[39m.\u001b[39;49mRprop, clip_range\u001b[39m=\u001b[39;49mtin_clip_range, return_step\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, max_iter\u001b[39m=\u001b[39;49m\u001b[39m25\u001b[39;49m, step_sizes\u001b[39m=\u001b[39;49m(\u001b[39m1e-06\u001b[39;49m, \u001b[39m5e-03\u001b[39;49m)))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gunder/Desktop/bachelor_project/notebooks/save_logits.ipynb#X40sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m get_avg_osr_auroc_across_splits(path_to_pretrained_weights_folder, tin_val_root_dir, device, tin_logits_dir \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39mfn/ia/test/\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m20\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, adv_attack\u001b[39m=\u001b[39mattack, number_of_splits\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/bachelor_project/our_modules/adv_tools.py:41\u001b[0m, in \u001b[0;36miterative_attack\u001b[0;34m(model, xs, ys, loss_func, torch_optim, clip_range, return_step, max_iter, **opt_kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     40\u001b[0m loss \u001b[39m=\u001b[39m loss_func(model(x[\u001b[39mNone\u001b[39;00m]), y)\n\u001b[0;32m---> 41\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     42\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     43\u001b[0m i \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    489\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    490\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "attack = (lambda x, y, model: iterative_attack(model, x, y, loss_func=lambda yhat, y: torch.max(yhat), torch_optim=torch.optim.Rprop, clip_range=tin_clip_range, return_step=False, max_iter=25, step_sizes=(1e-06, 5e-03)))\n",
    "get_avg_osr_auroc_across_splits(path_to_pretrained_weights_folder, tin_val_root_dir, device, tin_logits_dir + 'fn/ia/test/', 20, shuffle=False, adv_attack=attack, number_of_splits=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = np.array([1.2, 1.4, 1.6, 1.8, 2.0, 2.25, 2.50, 2.75, 3.0, 4.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.2 , 1.4 , 1.6 , 1.8 , 2.  , 2.25, 2.5 , 2.75, 3.  , 4.  ])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/gunder/Desktop/bachelor_project/notebooks/save_logits.ipynb Cell 20\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/gunder/Desktop/bachelor_project/notebooks/save_logits.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m fig, ax \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplots(\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gunder/Desktop/bachelor_project/notebooks/save_logits.ipynb#X24sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m ax\u001b[39m.\u001b[39mscatter(eps, np\u001b[39m.\u001b[39mzeros_like(eps), marker \u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m|\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gunder/Desktop/bachelor_project/notebooks/save_logits.ipynb#X24sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m plt\u001b[39m.\u001b[39mshow()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "ax.scatter(eps, np.zeros_like(eps), marker ='|')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fgsm_eps_experiment(eps, fn_osr_fgsm, tin_logits_dir + \"fn/fgsm/\", 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FP"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2-norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [01:50<00:00, 110.51s/it]\n",
      "100%|██████████| 1/1 [01:51<00:00, 111.36s/it]\n",
      "100%|██████████| 1/1 [01:44<00:00, 104.57s/it]\n",
      "100%|██████████| 1/1 [01:46<00:00, 106.95s/it]\n",
      "100%|██████████| 1/1 [01:54<00:00, 114.77s/it]\n",
      "100%|██████████| 1/1 [01:56<00:00, 116.35s/it]\n",
      "100%|██████████| 1/1 [01:58<00:00, 118.19s/it]\n",
      "100%|██████████| 1/1 [01:58<00:00, 118.30s/it]\n",
      "100%|██████████| 1/1 [01:58<00:00, 118.38s/it]\n",
      "100%|██████████| 1/1 [01:58<00:00, 118.23s/it]\n",
      "100%|██████████| 1/1 [02:06<00:00, 126.23s/it]\n",
      "100%|██████████| 1/1 [02:05<00:00, 125.65s/it]\n",
      "100%|██████████| 1/1 [02:05<00:00, 125.71s/it]\n",
      "100%|██████████| 1/1 [02:05<00:00, 125.98s/it]\n",
      "100%|██████████| 1/1 [02:09<00:00, 129.11s/it]\n",
      "100%|██████████| 1/1 [02:09<00:00, 129.12s/it]\n",
      "100%|██████████| 1/1 [02:10<00:00, 130.44s/it]\n",
      "100%|██████████| 1/1 [02:10<00:00, 130.27s/it]\n",
      "100%|██████████| 1/1 [02:11<00:00, 131.44s/it]\n",
      "100%|██████████| 1/1 [02:06<00:00, 126.17s/it]\n",
      "100%|██████████| 1/1 [01:36<00:00, 96.76s/it]\n",
      "100%|██████████| 1/1 [01:36<00:00, 96.73s/it]\n",
      "100%|██████████| 1/1 [01:36<00:00, 96.74s/it]\n",
      "100%|██████████| 1/1 [01:36<00:00, 96.77s/it]\n",
      "100%|██████████| 1/1 [01:36<00:00, 96.33s/it]\n",
      "100%|██████████| 1/1 [01:37<00:00, 97.18s/it]\n",
      "100%|██████████| 1/1 [01:37<00:00, 97.49s/it]\n",
      "100%|██████████| 1/1 [01:38<00:00, 98.66s/it]\n",
      "100%|██████████| 1/1 [01:38<00:00, 98.18s/it]\n",
      "100%|██████████| 1/1 [01:36<00:00, 96.41s/it]\n"
     ]
    }
   ],
   "source": [
    "# fgsm_eps_experiment(eps_list=eps, fgsm=fp_osr_fgsm, logdir=tin_logits_dir + \"fp/fgsm/two_norm/\", number_of_splits=1, norm_ord=None)\n",
    "# fgsm_eps_experiment(eps_list=eps, fgsm=fp_osr_fgsm, logdir=tin_logits_dir + \"fp/fgsm/inf_norm/\", number_of_splits=1, norm_ord=torch.inf)\n",
    "# fgsm_eps_experiment(eps_list=eps, fgsm=fp_osr_fgsm_sum_exp, logdir=tin_logits_dir + \"fp/fgsm/sum_exp/\", number_of_splits=1)\n",
    "#fgsm_eps_experiment(eps_list=eps, fgsm=fn_osr_fgsm, logdir=tin_logits_dir + \"fn/fgsm/inf_norm/\", number_of_splits=1, norm_ord=torch.inf)\n",
    "#fgsm_eps_experiment(eps_list=eps, fgsm=fn_osr_fgsm_log_msp, logdir=tin_logits_dir + \"fn/fgsm/log_msp/\", number_of_splits=1)\n",
    "#fgsm_eps_experiment(eps_list=eps, fgsm=fn_osr_fgsm_sum_exp, logdir=tin_logits_dir + \"fn/fgsm/sum_exp/\", number_of_splits=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Grad Norms \n",
    "Testing Odin paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_grad_norms_across_splits(path_to_pretrained_weights_folder, tin_val_root_dir, tin_grad_norms_dir + 'log_msp/', log_msp_loss, device, number_of_splits=5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Informed Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_informed_attack(tin_logits_dir + 'informed/fgsm/exp1/',\n",
    "                     tin_logits_dir + 'fn/fgsm/inf_norm/eps_0.139/', \n",
    "                     tin_logits_dir + 'fp/fgsm/two_norm/eps_0.0622/', 0)\n",
    "save_informed_attack(tin_logits_dir + 'informed/fgsm/exp2/', \n",
    "                     tin_logits_dir + 'plain/', \n",
    "                     tin_logits_dir + 'fp/fgsm/two_norm/eps_0.0622/', 0)\n",
    "save_informed_attack(tin_logits_dir + 'informed/fgsm/exp3/',\n",
    "                     tin_logits_dir + 'fn/fgsm/inf_norm/eps_0.139/', \n",
    "                     tin_logits_dir + 'plain/', 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
